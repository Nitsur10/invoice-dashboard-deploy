import fs from 'node:fs/promises'
import path from 'node:path'
import crypto from 'node:crypto'
import { execFile } from 'node:child_process'
import { promisify } from 'node:util'

import dotenv from 'dotenv'

const execFileAsync = promisify(execFile)

export async function bootstrapEnv() {
  await dotenv.config({ path: path.resolve(process.cwd(), '.env.local') })
  await dotenv.config()
}

/**
 * Postal Invoice OCR Pipeline
 *
 * Required environment variables:
 * - SUPABASE_URL
 * - SUPABASE_SERVICE_ROLE_KEY
 * - SUPABASE_INVOICES_TABLE (optional, defaults to "invoices")
 * - AZURE_TENANT_ID
 * - AZURE_CLIENT_ID
 * - AZURE_CLIENT_SECRET
 * - POSTAL_ONEDRIVE_DRIVE_ID
 * - POSTAL_ONEDRIVE_FOLDER_PATH (e.g. "Rudra Projects/Invoice Management/Postal Invoices")
 * - OPENAI_API_KEY (stored as the OpenAiVision credential)
 *
 * Optional environment variables:
 * - OPENAI_VISION_MODEL (defaults to gpt-4.1-mini)
 * - POSTAL_LOOKBACK_HOURS (defaults to 24)
 */

import { createClient, type SupabaseClient } from '@supabase/supabase-js'

type GraphDriveItem = {
  id: string
  name: string
  file?: { mimeType?: string }
  createdDateTime: string
  lastModifiedDateTime: string
  webUrl: string
  parentReference?: { path?: string; driveId?: string }
  size?: number
}

type InvoicePayload = {
  invoice_number: string | null
  invoice_date: string | null
  due_date: string | null
  currency: string | null
  subtotal: number | null
  gst_total: number | null
  total: number | null
  amount_due: number | null
  supplier_name: string | null
  supplier_abn: string | null
  supplier_email: string | null
  customer_name: string | null
  customer_abn: string | null
  bank_bsb: string | null
  bank_account: string | null
  payment_reference: string | null
  line_1_desc: string | null
  line_1_qty: number | null
  line_1_unit_price: number | null
  notes: string | null
  ocr_confidence: number | null
  file_checksum: string
  file_name: string
  file_url?: string
  source: 'postal_ocr'
  ocr_model?: string
  message_id?: string | null
}

type PostalIngestLogStatus = 'processed' | 'skipped_duplicate' | 'exception'

const GRAPH_TOKEN_URL = (tenant: string) =>
  `https://login.microsoftonline.com/${tenant}/oauth2/v2.0/token`
const GRAPH_BASE_URL = 'https://graph.microsoft.com/v1.0'

async function fileExists(filePath: string): Promise<boolean> {
  try {
    await fs.access(filePath)
    return true
  } catch {
    return false
  }
}

async function convertPdfToPng(pdfPath: string, outputDir: string): Promise<string> {
  try {
    await execFileAsync('qlmanage', ['-t', '-s', '2048', '-o', outputDir, pdfPath])
  } catch (error) {
    throw new Error(
      `qlmanage conversion failed. Ensure this script runs on macOS with qlmanage available. Original error: ${error}`
    )
  }

  const baseName = path.basename(pdfPath)
  const expectedName = `${baseName}.png`
  const expectedPath = path.join(outputDir, expectedName)
  if (await fileExists(expectedPath)) {
    return expectedPath
  }

  const files = await fs.readdir(outputDir)
  const pngMatch = files.find((file) =>
    file.startsWith(baseName.replace(/\.pdf$/i, '')) && file.toLowerCase().endsWith('.png')
  )

  if (pngMatch) {
    return path.join(outputDir, pngMatch)
  }

  throw new Error('Could not locate PNG preview generated by qlmanage')
}

async function fetchDriveThumbnail(
  token: string,
  driveId: string,
  itemId: string
): Promise<{ buffer: Buffer; mimeType: string } | null> {
  const url = `${GRAPH_BASE_URL}/drives/${driveId}/items/${itemId}/thumbnails/0/large`
  const res = await fetch(url, {
    headers: { Authorization: `Bearer ${token}` },
  })

  if (!res.ok) {
    return null
  }

  const data = (await res.json()) as {
    url?: string
    contentType?: string
  }

  if (!data?.url) {
    return null
  }

  const imageRes = await fetch(data.url, {
    headers: { Authorization: `Bearer ${token}` },
  })

  if (!imageRes.ok) {
    return null
  }

  const arrayBuffer = await imageRes.arrayBuffer()
  return {
    buffer: Buffer.from(arrayBuffer),
    mimeType: imageRes.headers.get('Content-Type') || data.contentType || 'image/png',
  }
}

const REQUIRED_ENV = [
  'SUPABASE_URL',
  'SUPABASE_SERVICE_ROLE_KEY',
  'POSTAL_ONEDRIVE_DRIVE_ID',
  'POSTAL_ONEDRIVE_FOLDER_PATH',
  'OPENAI_API_KEY',
  'AZURE_TENANT_ID',
  'AZURE_CLIENT_ID',
  'AZURE_CLIENT_SECRET',
] as const

function assertEnv() {
  const missing = REQUIRED_ENV.filter((key) => !process.env[key])
  if (missing.length > 0) {
    throw new Error(
      `Missing required environment variables: ${missing.join(', ')}`
    )
  }
}

async function getGraphToken(): Promise<string> {
  const body = new URLSearchParams({
    client_id: process.env.AZURE_CLIENT_ID!,
    client_secret: process.env.AZURE_CLIENT_SECRET!,
    scope: 'https://graph.microsoft.com/.default',
    grant_type: 'client_credentials',
  })

  const res = await fetch(GRAPH_TOKEN_URL(process.env.AZURE_TENANT_ID!), {
    method: 'POST',
    headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
    body,
  })

  if (!res.ok) {
    const txt = await res.text()
    throw new Error(`Failed to obtain Graph token: ${res.status} ${txt}`)
  }

  const data = (await res.json()) as { access_token: string }
  return data.access_token
}

async function listRecentPostalFiles(
  token: string,
  options: {
    driveId: string
    folderPath: string
    folderId?: string
    userPrincipalName?: string
    createdAfter?: string
  }
): Promise<GraphDriveItem[]> {
  const encodePath = (path: string) =>
    path
      .split('/')
      .map((segment) => encodeURIComponent(segment))
      .join('/')

  const candidatePaths = Array.from(
    new Set([
      options.folderPath,
      options.folderPath.startsWith('Documents/')
        ? options.folderPath
        : `Documents/${options.folderPath}`,
      options.folderPath.startsWith('Shared Documents/')
        ? options.folderPath
        : `Shared Documents/${options.folderPath}`,
      `Shared Documents/${options.folderPath}`,
    ])
  )

  let lastError: Error | null = null

  const urlFromPath = (candidate: string) =>
    new URL(
      `${GRAPH_BASE_URL}/drives/${options.driveId}/root:/${encodePath(
        candidate
      )}:/children`
    )

  const urlFromId = (folderId: string) =>
    new URL(
      `${GRAPH_BASE_URL}/drives/${options.driveId}/items/${folderId}/children`
    )

  const urlFromUserId = (folderId: string, userPrincipalName: string) =>
    new URL(
      `${GRAPH_BASE_URL}/users/${encodeURIComponent(
        userPrincipalName
      )}/drive/items/${folderId}/children`
    )

  const urlFromUserPath = (path: string, userPrincipalName: string) =>
    new URL(
      `${GRAPH_BASE_URL}/users/${encodeURIComponent(
        userPrincipalName
      )}/drive/root:/${encodePath(path)}:/children`
    )

  const requesters: Array<{ label: string; url: URL }> = []

  if (options.folderId) {
    requesters.push({
      label: `folderId=${options.folderId}`,
      url: urlFromId(options.folderId),
    })
    if (options.userPrincipalName) {
      requesters.push({
        label: `user=${options.userPrincipalName} folderId=${options.folderId}`,
        url: urlFromUserId(options.folderId, options.userPrincipalName),
      })
    }
  }

  for (const candidate of candidatePaths) {
    requesters.push({ label: `path="${candidate}"`, url: urlFromPath(candidate) })
    if (options.userPrincipalName) {
      requesters.push({
        label: `user=${options.userPrincipalName} path="${candidate}"`,
        url: urlFromUserPath(candidate, options.userPrincipalName),
      })
    }
  }

  for (const requester of requesters) {
    const url = requester.url
    url.searchParams.set('$top', '200')

    const res = await fetch(url.toString(), {
      headers: { Authorization: `Bearer ${token}` },
    })

    if (!res.ok) {
      const txt = await res.text()
      const error = new Error(
        `Failed to list postal files (${requester.label}): ${res.status} ${res.statusText} ${txt}`
      )
      console.warn(error.message)
      lastError = error
      continue
    }

    const data = (await res.json()) as {
      value: GraphDriveItem[]
      '@odata.nextLink'?: string
    }

    let items = data.value
    let nextLink = data['@odata.nextLink']

    while (nextLink) {
      const nextRes = await fetch(nextLink, {
        headers: { Authorization: `Bearer ${token}` },
      })
      if (!nextRes.ok) {
        const txt = await nextRes.text()
        console.warn(
          `‚ö†Ô∏è Failed to fetch next page of postal files (path="${candidate}"): ${nextRes.status} ${txt}`
        )
        break
      }

      const nextData = (await nextRes.json()) as {
        value: GraphDriveItem[]
        '@odata.nextLink'?: string
      }
      items = items.concat(nextData.value)
      nextLink = nextData['@odata.nextLink']
    }

  const filtered = items.filter((item) => {
    if (!item.file?.mimeType?.toLowerCase().includes('pdf')) return false
    if (!options.createdAfter) return true
    const createdAt = new Date(item.createdDateTime).getTime()
    const cutoff = new Date(options.createdAfter).getTime()
    return createdAt >= cutoff
  })

  if (filtered.length === 0) {
    console.log(
      `‚ÑπÔ∏è  No postal invoices found via ${requester.label} within the current lookback window.`
    )
  } else if (
    requester.label !== `path="${options.folderPath}"`
  ) {
    console.log(
      `‚ÑπÔ∏è  Using resolved OneDrive locator ${requester.label} for postal invoices.`
      )
    }

    return filtered
  }

  if (lastError) {
    throw lastError
  }

  throw new Error('Failed to list postal files: no candidate paths succeeded')
}

async function downloadPostalFile(
  token: string,
  options: { driveId: string; itemId: string }
): Promise<Buffer> {
  const res = await fetch(
    `${GRAPH_BASE_URL}/drives/${options.driveId}/items/${options.itemId}/content`,
    {
      headers: { Authorization: `Bearer ${token}` },
    }
  )

  if (!res.ok) {
    const txt = await res.text()
    throw new Error(
      `Failed to download file ${options.itemId}: ${res.status} ${txt}`
    )
  }

  const arrayBuffer = await res.arrayBuffer()
  return Buffer.from(arrayBuffer)
}

function sha256(buffer: Buffer): string {
  const hash = crypto.createHash('sha256')
  hash.update(buffer)
  return hash.digest('hex')
}

type OpenAiVisionResponse = {
  invoice_number?: string | null
  invoice_date?: string | null
  due_date?: string | null
  currency?: string | null
  subtotal?: number | null
  gst_total?: number | null
  total?: number | null
  amount_due?: number | null
  supplier?: {
    name?: string | null
    abn?: string | null
    email?: string | null
  }
  customer?: {
    name?: string | null
    abn?: string | null
  }
  bank?: {
    bsb?: string | null
    account?: string | null
  }
  payment_reference?: string | null
  line_items?: Array<{
    description?: string | null
    quantity?: number | null
    unit_price?: number | null
  }>
  notes?: string | null
  confidence?: {
    invoice_number?: number | null
    supplier?: number | null
    totals?: number | null
  }
  message_id?: string | null
}

async function callOpenAiVision(
  fileBuffer: Buffer,
  filename: string,
  mimeType: string
): Promise<{ payload: OpenAiVisionResponse; model: string }> {
  const openaiKey = process.env.OPENAI_API_KEY!
  const model = process.env.OPENAI_VISION_MODEL || 'gpt-4.1-mini'

  const form = new FormData()
  form.append('purpose', 'vision')
  form.append('file', new Blob([fileBuffer], { type: mimeType }), filename)

  const uploadRes = await fetch('https://api.openai.com/v1/files', {
    method: 'POST',
    headers: {
      Authorization: `Bearer ${openaiKey}`,
    },
    body: form,
  })

  if (!uploadRes.ok) {
    const txt = await uploadRes.text()
    throw new Error(`OpenAI file upload failed: ${uploadRes.status} ${txt}`)
  }

  const uploadJson = (await uploadRes.json()) as { id: string }

  const prompt = `You are processing an Australian business invoice. Return JSON matching this schema:
{
  "invoice_number": string | null,
  "invoice_date": "YYYY-MM-DD" | null,
  "due_date": "YYYY-MM-DD" | null,
  "currency": string | null,
  "subtotal": number | null,
  "gst_total": number | null,
  "total": number,
  "amount_due": number | null,
  "supplier": {
    "name": string | null,
    "abn": string | null,
    "email": string | null
  },
  "customer": {
    "name": string | null,
    "abn": string | null
  },
  "bank": {
    "bsb": string | null,
    "account": string | null
  },
  "payment_reference": string | null,
  "line_items": [
    {
      "description": string,
      "quantity": number | null,
      "unit_price": number | null
    }
  ],
  "notes": string | null,
  "confidence": {
    "invoice_number": number | null,
    "supplier": number | null,
    "totals": number | null
  },
  "message_id": string | null
}

Return null where information is not present.`

  const responseRes = await fetch('https://api.openai.com/v1/responses', {
    method: 'POST',
    headers: {
      Authorization: `Bearer ${openaiKey}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model,
      input: [
        {
          role: 'user',
      content: [
        {
          type: 'input_image',
          image_url: { file_id: uploadJson.id, mime_type: mimeType },
        },
        { type: 'text', text: prompt },
      ],
    },
      ],
      response_format: { type: 'json_object' },
      max_output_tokens: 1024,
    }),
  })

  if (!responseRes.ok) {
    const txt = await responseRes.text()
    throw new Error(`OpenAI response failed: ${responseRes.status} ${txt}`)
  }

  const responseJson = await responseRes.json()

  let payload: OpenAiVisionResponse | null = null

  // Responses API may surface output_text or structured content
  const outputText =
    responseJson.output_text ??
    responseJson.output?.[0]?.content?.[0]?.text ??
    responseJson.content?.[0]?.text

  if (outputText) {
    try {
      payload = JSON.parse(outputText)
    } catch (error) {
      throw new Error(`Failed to parse OpenAI JSON output: ${outputText}`)
    }
  } else if (responseJson.content) {
    const textChunks = responseJson.content
      .flatMap((chunk: any) => chunk.text || [])
      .join('')
    if (textChunks) {
      payload = JSON.parse(textChunks)
    }
  }

  if (!payload) {
    throw new Error('OpenAI response missing payload content')
  }

  return { payload, model }
}

function mapToInvoicePayload(
  raw: OpenAiVisionResponse,
  base: {
    checksum: string
    filename: string
  }
): InvoicePayload {
  const firstLine = raw.line_items?.[0]
  const supplierConfidence = raw.confidence?.supplier ?? null
  const totalsConfidence = raw.confidence?.totals ?? null
  const invoiceConfidence = raw.confidence?.invoice_number ?? null

  const confidences = [
    supplierConfidence,
    totalsConfidence,
    invoiceConfidence,
  ].filter((value): value is number => typeof value === 'number')

  const averageConfidence =
    confidences.length > 0
      ? confidences.reduce((sum, value) => sum + value, 0) / confidences.length
      : null

  return {
    invoice_number: raw.invoice_number ?? null,
    invoice_date: raw.invoice_date ?? null,
    due_date: raw.due_date ?? null,
    currency: raw.currency ?? null,
    subtotal: raw.subtotal ?? null,
    gst_total: raw.gst_total ?? null,
    total: raw.total ?? null,
    amount_due: raw.amount_due ?? null,
    supplier_name: raw.supplier?.name ?? null,
    supplier_abn: raw.supplier?.abn ?? null,
    supplier_email: raw.supplier?.email ?? null,
    customer_name: raw.customer?.name ?? null,
    customer_abn: raw.customer?.abn ?? null,
    bank_bsb: raw.bank?.bsb ?? null,
    bank_account: raw.bank?.account ?? null,
    payment_reference: raw.payment_reference ?? null,
    line_1_desc: firstLine?.description ?? null,
    line_1_qty: firstLine?.quantity ?? null,
    line_1_unit_price: firstLine?.unit_price ?? null,
    notes: raw.notes ?? null,
    ocr_confidence: averageConfidence,
    file_checksum: base.checksum,
    file_name: base.filename,
    source: 'postal_ocr',
    ocr_model: process.env.OPENAI_VISION_MODEL || 'gpt-4.1-mini',
    message_id: raw.message_id ?? null,
  }
}

function validateInvoicePayload(payload: InvoicePayload): {
  ok: boolean
  issues: string[]
} {
  const issues: string[] = []

  if (!payload.total || payload.total <= 0) {
    issues.push('Missing or invalid total amount')
  }

  if (!payload.supplier_name) {
    issues.push('Missing supplier name')
  }

  if (payload.gst_total && payload.total) {
    const expected = (payload.total ?? 0) / 11
    const delta = Math.abs(expected - payload.gst_total)
    if (delta > 0.1 * expected) {
      issues.push('GST total outside 10% tolerance')
    }
  }

  return { ok: issues.length === 0, issues }
}

async function upsertInvoice(
  supabase: SupabaseClient,
  payload: InvoicePayload,
  options: { supabaseTable: string }
) {
  let duplicateQuery = supabase
    .from(options.supabaseTable)
    .select('id, invoice_number')
    .limit(1)
  if (payload.invoice_number) {
    duplicateQuery = duplicateQuery.or(
      `file_checksum.eq.${payload.file_checksum},invoice_number.eq.${payload.invoice_number}`
    )
  } else {
    duplicateQuery = duplicateQuery.eq('file_checksum', payload.file_checksum)
  }

  const { data: duplicate } = await duplicateQuery.maybeSingle()
  if (duplicate) {
    return {
      status: 'duplicate',
      invoiceId: duplicate.id,
    } as const
  }

  const insertPayload = {
    ...payload,
    created_at: new Date().toISOString(),
  }

  const { data, error } = await supabase
    .from(options.supabaseTable)
    .insert(insertPayload)
    .select('id')
    .maybeSingle()

  if (error) {
    throw error
  }

  return {
    status: 'inserted',
    invoiceId: data?.id ?? null,
  } as const
}

async function logPostalIngest(
  supabase: SupabaseClient,
  options: {
    status: PostalIngestLogStatus
    reason?: string
    fileName: string
    fileChecksum: string
    invoiceNumber?: string | null
    supabaseId?: string | null
  }
) {
  await supabase.from('postal_ingest_log').insert({
    status: options.status,
    reason: options.reason ?? null,
    file_name: options.fileName,
    file_checksum: options.fileChecksum,
    invoice_number: options.invoiceNumber ?? null,
    supabase_id: options.supabaseId ?? null,
    created_at: new Date().toISOString(),
  })
}

async function processPostalInvoices() {
  assertEnv()

  const driveId = process.env.POSTAL_ONEDRIVE_DRIVE_ID!
  const folderPath = process.env.POSTAL_ONEDRIVE_FOLDER_PATH!
  const folderId = process.env.POSTAL_ONEDRIVE_FOLDER_ID
  const userPrincipalName = process.env.POSTAL_ONEDRIVE_USER_PRINCIPAL
  const supabaseTable = process.env.SUPABASE_INVOICES_TABLE || 'invoices'
  const dryRun = process.env.POSTAL_DRY_RUN === 'true'
  const maxFiles = Number(process.env.POSTAL_MAX_FILES || '0')

  const lookbackDays = Number(process.env.POSTAL_BACKFILL_DAYS || '30')
  const createdAfter = new Date(Date.now() - lookbackDays * 24 * 60 * 60 * 1000)
    .toISOString()
    .replace(/\.\d{3}Z$/, 'Z')

  const supabaseUrl = process.env.SUPABASE_URL!
  const supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY!
  const supabase = createClient(supabaseUrl, supabaseKey, {
    auth: { persistSession: false },
  })

  const graphToken = await getGraphToken()
  console.log(
    `üìÇ Listing postal invoices in ${folderPath} (created after ${createdAfter})`
  )
  let items = await listRecentPostalFiles(graphToken, {
    driveId,
    folderPath,
    folderId,
    userPrincipalName,
    createdAfter,
  })

  if (maxFiles > 0 && items.length > maxFiles) {
    console.log(`‚ÑπÔ∏è  Limiting processing to first ${maxFiles} file(s) (POSTAL_MAX_FILES=${maxFiles}).`)
    items = items.slice(0, maxFiles)
  }

  if (items.length === 0) {
    console.log('‚úÖ No new postal invoices detected.')
    return
  }

  console.log(`üìÑ Found ${items.length} candidate file(s). Processing...`)

  if (dryRun) {
    console.log('üìù Dry run enabled (POSTAL_DRY_RUN=true) ‚Äî no files will be processed.')
    const sample = items.slice(0, 10).map((item) => `   ‚Ä¢ ${item.name} (${item.id})`)
    if (sample.length > 0) {
      console.log('   Sample files:')
      console.log(sample.join('\n'))
      if (items.length > sample.length) {
        console.log(`   ‚Ä¶and ${items.length - sample.length} more`)
      }
    }
    return
  }

  for (const item of items) {
    console.log(`\n‚û°Ô∏è  Processing ${item.name} (${item.id})`)
    try {
      const buffer = await downloadPostalFile(graphToken, {
        driveId,
        itemId: item.id,
      })

      const checksum = sha256(buffer)
      const tempDir = path.join(process.cwd(), '.postal-tmp')
      await fs.mkdir(tempDir, { recursive: true })
      const tmpPdfPath = path.join(tempDir, item.name)
      await fs.writeFile(tmpPdfPath, buffer)

      let imageBuffer = buffer
      let imageName = item.name
      let mimeType = item.file?.mimeType || 'application/pdf'

      if (item.file?.mimeType?.toLowerCase() === 'application/pdf') {
        console.log('   ‚Ä¢ Requesting OneDrive thumbnail preview...')
        const thumbnail = await fetchDriveThumbnail(graphToken, driveId, item.id)

        if (thumbnail) {
          imageBuffer = thumbnail.buffer
          mimeType = thumbnail.mimeType || 'image/png'
          imageName = `${path.basename(item.name, '.pdf')}.preview.png`
          console.log('   ‚Ä¢ Using OneDrive thumbnail preview for OCR.')
        } else {
          console.log('   ‚Ä¢ Thumbnail unavailable, converting PDF via qlmanage...')
          const pngPath = await convertPdfToPng(tmpPdfPath, tempDir)
          imageBuffer = await fs.readFile(pngPath)
          imageName = path.basename(pngPath)
          mimeType = 'image/png'
          console.log(`   ‚Ä¢ Generated preview: ${imageName}`)
        }
      }

      console.log(`   ‚Ä¢ SHA-256: ${checksum}`)
      console.log('   ‚Ä¢ Uploading to OpenAI Vision...')
      const { payload: rawPayload, model: visionModel } =
        await callOpenAiVision(imageBuffer, imageName, mimeType)

      console.log(`   ‚Ä¢ Vision model: ${visionModel}`)
      const invoicePayload = mapToInvoicePayload(rawPayload, {
        checksum,
        filename: item.name,
      })

      const validation = validateInvoicePayload(invoicePayload)
      if (!validation.ok) {
        const reason = `Validation failed: ${validation.issues.join(', ')}`
        console.warn(`   ‚ö†Ô∏è  ${reason}`)
        await logPostalIngest(supabase, {
          status: 'exception',
          reason,
          fileName: item.name,
          fileChecksum: checksum,
          invoiceNumber: invoicePayload.invoice_number,
        })
        continue
      }

      const result = await upsertInvoice(supabase, invoicePayload, {
        supabaseTable,
      })
      if (result.status === 'duplicate') {
        console.log('   üîÅ Duplicate detected, skipping Supabase insert')
        await logPostalIngest(supabase, {
          status: 'skipped_duplicate',
          fileName: item.name,
          fileChecksum: checksum,
          invoiceNumber: invoicePayload.invoice_number,
          supabaseId: result.invoiceId,
        })
      } else {
        console.log(`   ‚úÖ Inserted invoice (id: ${result.invoiceId ?? 'n/a'})`)
        await logPostalIngest(supabase, {
          status: 'processed',
          fileName: item.name,
          fileChecksum: checksum,
          invoiceNumber: invoicePayload.invoice_number,
          supabaseId: result.invoiceId,
        })
      }
    } catch (error) {
      console.error(`   ‚ùå Failed to process ${item.name}`, error)
      await logPostalIngest(supabase, {
        status: 'exception',
        reason: error instanceof Error ? error.message : 'Unknown error',
        fileName: item.name,
        fileChecksum: 'n/a',
      })
    }
  }
}

async function main() {
  await bootstrapEnv()
  try {
    await processPostalInvoices()
  } catch (error) {
    console.error('Postal OCR pipeline failed:', error)
    process.exitCode = 1
  }
}

void main()
